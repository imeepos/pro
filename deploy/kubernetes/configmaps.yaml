# Configuration Maps for Weibo Crawler System
apiVersion: v1
kind: ConfigMap
metadata:
  name: crawler-config
  namespace: weibo-crawler
  labels:
    app: weibo-crawler
    component: config
data:
  NODE_ENV: "production"
  PORT: "3000"
  LOG_LEVEL: "info"
  LOG_FORMAT: "json"

  # Database connection settings
  POSTGRES_HOST: "postgres-service"
  POSTGRES_PORT: "5432"
  POSTGRES_DB: "pro"

  MONGODB_DATABASE: "pro"

  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"

  RABBITMQ_HOST: "rabbitmq-service"
  RABBITMQ_PORT: "5672"
  RABBITMQ_VHOST: "/"

  MINIO_ENDPOINT: "minio-service"
  MINIO_PORT: "9000"
  MINIO_USE_SSL: "false"

  # Crawler performance settings
  CRAWLER_CONCURRENCY: "3"
  CRAWLER_DELAY_MIN: "2000"
  CRAWLER_DELAY_MAX: "5000"
  CRAWLER_MAX_RETRIES: "3"
  CRAWLER_HEADLESS: "true"
  CRAWLER_MAX_PAGES: "50"

  # Anti-detection settings
  ANTI_DETECTION_STEALTH_SCRIPT: "true"
  ANTI_DETECTION_FINGERPRINTING: "true"
  ANTI_DETECTION_UA_ROTATION: "true"
  ANTI_DETECTION_TIMEZONE: "Asia/Shanghai"
  ANTI_DETECTION_WEBGL: "true"
  ANTI_DETECTION_CANVAS: "true"

  # Rate monitoring
  RATE_MONITORING_ENABLED: "true"
  RATE_WINDOW_SIZE_MS: "60000"
  RATE_MAX_REQUESTS_PER_WINDOW: "10"

  # Adaptive delay
  ADAPTIVE_DELAY_ENABLED: "true"
  ADAPTIVE_DELAY_INCREASE_FACTOR: "1.5"
  ADAPTIVE_DELAY_DECREASE_FACTOR: "0.8"
  ADAPTIVE_DELAY_MAX_MS: "30000"
  ADAPTIVE_DELAY_MIN_MS: "1000"

# Browser pool settings
  BROWSER_POOL_SIZE: "5"
  BROWSER_MAX_REUSE: "100"
  BROWSER_IDLE_TIMEOUT: "300000"

---
# API configuration for WebSocket & PubSub
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-config
  namespace: weibo-crawler
  labels:
    app: weibo-crawler
    component: api
data:
  PUBSUB_DRIVER: "redis"
  PUBSUB_NAMESPACE: "@pro/api"
  PUBSUB_REDIS_MODE: "standalone"
  PUBSUB_REDIS_HOST: "redis-service"
  PUBSUB_REDIS_PORT: "6379"
  PUBSUB_REDIS_DB: "0"
  WS_HANDSHAKE_WINDOW_MS: "10000"
  WS_MAX_HANDSHAKES_PER_IP: "20"
  WS_HANDSHAKE_COOLDOWN_MS: "15000"
  WS_FAILURE_WINDOW_MS: "60000"
  WS_MAX_FAILURES_PER_IP: "5"
  WS_FAILURE_COOLDOWN_MS: "120000"
  WS_MAX_CONNECTIONS_PER_USER: "8"
  WS_MAX_CONNECTIONS_PER_IP: "12"
---
# Redis configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: weibo-crawler
  labels:
    app: weibo-crawler
    component: redis
data:
  redis.conf: |
    # Redis production configuration
    bind 0.0.0.0
    port 6379
    timeout 0
    keepalive 300
    tcp-backlog 511

    # Memory management
    maxmemory 1gb
    maxmemory-policy allkeys-lru

    # Persistence
    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes
    dbfilename dump.rdb
    dir /data

    # Security
    protected-mode yes
    # requirepass will be set via secret

    # Performance
    tcp-keepalive 60
    lazyfree-lazy-eviction no
    lazyfree-lazy-expire no
    lazyfree-lazy-server-del no

---
# Nginx configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: weibo-crawler
  labels:
    app: weibo-crawler
    component: nginx
data:
  nginx.conf: |
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log warn;
    pid /var/run/nginx.pid;

    events {
        worker_connections 1024;
        use epoll;
        multi_accept on;
    }

    http {
        include /etc/nginx/mime.types;
        default_type application/octet-stream;

        log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';

        access_log /var/log/nginx/access.log main;

        sendfile on;
        tcp_nopush on;
        tcp_nodelay on;
        keepalive_timeout 65;
        types_hash_max_size 2048;
        server_tokens off;

        # Rate limiting
        limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
        limit_req_zone $binary_remote_addr zone=health:10m rate=30r/s;

        # Gzip compression
        gzip on;
        gzip_vary on;
        gzip_min_length 1024;
        gzip_proxied any;
        gzip_comp_level 6;
        gzip_types
            text/plain
            text/css
            text/xml
            text/javascript
            application/json
            application/javascript
            application/xml+rss
            image/svg+xml;

        upstream crawler_backend {
            server crawler-service:3000;
            keepalive 32;
        }

        server {
            listen 80;
            server_name _;

            # Health check
            location /health {
                access_log off;
                limit_req zone=health burst=5 nodelay;
                return 200 "healthy\n";
                add_header Content-Type text/plain;
            }

            # API endpoints
            location /api/ {
                limit_req zone=api burst=20 nodelay;

                proxy_pass http://crawler_backend;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;

                proxy_connect_timeout 60s;
                proxy_send_timeout 60s;
                proxy_read_timeout 60s;
            }

            # Default proxy
            location / {
                proxy_pass http://crawler_backend;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
                proxy_cache_bypass $http_upgrade;
            }
        }
    }

---
# PostgreSQL init scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-init
  namespace: weibo-crawler
  labels:
    app: weibo-crawler
    component: postgres
data:
  01-init.sql: |
    -- Create database and user
    CREATE DATABASE pro;
    CREATE USER pro WITH ENCRYPTED PASSWORD 'temp_password';
    GRANT ALL PRIVILEGES ON DATABASE pro TO pro;

    -- Connect to pro database and create extensions
    \c pro;
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    CREATE EXTENSION IF NOT EXISTS "pg_trgm";

    -- Create indexes for performance
    -- Indexes will be created by the application schema
