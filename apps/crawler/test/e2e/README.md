# 微博爬取系统端到端集成测试套件

> **数字时代的测试艺术品** - 验证基于MediaCrawler增强的完整微博爬取架构

## 🎯 概述

这是一个全面的端到端集成测试套件，专门为验证基于MediaCrawler增强的微博爬取系统而设计。测试套件覆盖了从基础功能到复杂场景的所有方面，确保系统在各种条件下的稳定性、性能和可靠性。

## 📋 测试架构

### 核心测试模块

1. **完整数据流程集成测试** (`integration/`)
   - 验证从任务创建到数据存储的完整链路
   - 测试多模式爬取的协同工作
   - 验证数据清洗和结构化的准确性

2. **性能压力测试套件** (`performance/`)
   - 基准性能测试和压力测试
   - 高并发和大数据量测试
   - 长时间稳定性验证

3. **错误恢复和故障转移测试** (`recovery/`)
   - 网络中断自动恢复测试
   - 账号失效故障转移验证
   - 熔断器机制测试

4. **数据一致性验证测试** (`data-consistency/`)
   - 数据完整性和一致性检查
   - 重复数据检测
   - 增量数据正确性验证

5. **监控和告警系统测试** (`monitoring/`)
   - 请求监控准确性验证
   - 任务状态追踪完整性测试
   - 异常情况告警机制验证

## 🚀 快速开始

### 环境要求

- Node.js >= 18.0.0
- pnpm 包管理器
- 足够的系统资源用于压力测试

### 安装依赖

```bash
cd apps/crawler
pnpm install
```

### 运行所有测试

```bash
# 运行完整的端到端测试套件
pnpm run test:e2e

# 运行特定测试套件
pnpm run test:e2e -- --testNamePattern="完整数据流程集成测试"
```

### 使用测试运行器

```bash
# 编译并运行自定义测试
npx ts-node test/e2e/utils/test-runner.ts
```

## 📊 测试配置

### Jest 配置 (test/jest-e2e.json)

```json
{
  "preset": "ts-jest",
  "testEnvironment": "node",
  "testTimeout": 300000,
  "maxWorkers": 4,
  "setupFilesAfterEnv": ["<rootDir>/e2e/setup.ts"]
}
```

### 环境变量

```bash
# 测试环境配置
NODE_ENV=test
CRAWLER_CONFIG_MAX_PAGES=5
CRAWLER_CONFIG_REQUEST_DELAY_MIN=100
CRAWLER_CONFIG_REQUEST_DELAY_MAX=500
MONITORING_CONFIG_ENABLE_METRICS=true
MONITORING_CONFIG_ENABLE_ALERTS=true
```

## 🧪 测试用例详解

### 1. 完整数据流程集成测试

#### 基础搜索爬取流程
- **目标**: 验证完整的搜索爬取流程
- **验证点**: 爬取成功率、数据完整性、执行时间
- **预期结果**: 成功率 > 95%，执行时间 < 60秒

#### 多模式爬取流程
- **目标**: 验证搜索、详情、创作者等多模式协同工作
- **验证点**: 模式间数据传递、性能指标、错误处理
- **预期结果**: 所有模式正常执行，数据传递正确

### 2. 性能压力测试

#### 高并发压力测试
- **目标**: 验证系统在高并发下的稳定性
- **配置**: 10个并发任务，每个任务包含多个爬取模式
- **验证点**: 成功率、响应时间、资源使用率
- **预期结果**: 成功率 > 80%，平均响应时间 < 30秒

#### 内存CPU压力测试
- **目标**: 验证系统在资源压力下的表现
- **配置**: 8个并发任务，包含复杂的数据处理
- **验证点**: 内存使用、CPU使用率、系统稳定性
- **预期结果**: 内存使用 < 300MB，CPU使用率 < 85%

### 3. 错误恢复测试

#### 网络中断恢复
- **目标**: 验证网络中断后的自动恢复能力
- **模拟场景**: 60%网络故障率，2秒恢复时间
- **验证点**: 重试机制、恢复成功率、总执行时间
- **预期结果**: 恢复成功率 > 90%，总时间 < 45秒

#### 账号失效故障转移
- **目标**: 验证账号失效时的自动切换
- **模拟场景**: 40%账号故障率
- **验证点**: 账号切换次数、最终成功率
- **预期结果**: 自动切换成功，最终成功率 > 85%

### 4. 数据一致性测试

#### 数据完整性验证
- **目标**: 验证爬取数据的完整性
- **验证点**: 必要字段存在性、数据类型正确性、内容有效性
- **评分标准**: 完整性分数 > 70分

#### 重复数据检测
- **目标**: 验证重复数据的检测和处理
- **验证点**: ID重复检测、内容重复检测、时间序列一致性
- **预期结果**: 无重复数据，时间序列正确

### 5. 监控告警测试

#### 请求监控验证
- **目标**: 验证请求监控数据的准确性
- **验证点**: 请求统计、成功率、平均响应时间
- **预期结果**: 监控数据与实际执行一致

#### 异常告警测试
- **目标**: 验证异常情况的告警机制
- **模拟场景**: CPU使用率90%、错误率50%
- **验证点**: 告警触发、告警级别、告警内容
- **预期结果**: 正确触发相应级别的告警

## 📈 测试报告

### 报告类型

1. **HTML报告**: 详细的可视化报告，包含图表和统计
2. **JSON报告**: 机器可读的结构化数据
3. **Markdown摘要**: 简洁的文字总结报告

### 报告位置

所有测试报告生成在 `test/reports/` 目录下：

```
test/reports/
├── complete-data-flow_2024-01-15T10-30-00-000Z.html
├── performance-stress_2024-01-15T10-35-00-000Z.html
├── test-summary.md
└── E2E_TEST_SUITE_OVERALL_2024-01-15T10-40-00-000Z.html
```

### 报告内容

- **执行摘要**: 总体统计和关键指标
- **性能分析**: 响应时间、资源使用、吞吐量
- **问题识别**: 失败测试、性能瓶颈、异常模式
- **改进建议**: 基于测试结果的优化建议

## 🔧 自定义测试

### 添加新测试用例

1. 在相应的测试文件中添加新的测试函数：

```typescript
it('应该处理新的测试场景', async () => {
  const testMessage = TestUtils.createTestSubTaskMessage({
    keyword: '新测试关键词',
    taskId: 99999
  });

  const result = await crawlerService.crawl(testMessage);

  expect(result.success).toBe(true);
  expect(result.pageCount).toBeGreaterThan(0);
});
```

2. 更新测试运行器配置：

```typescript
// test-runner.ts 中添加新的测试
private async runNewCustomTest(): Promise<any> {
  await TestUtils.sleep(2000);
  return { customMetric: 100, success: true };
}
```

### 配置测试参数

修改 `TEST_CONFIG` 对来自定义测试行为：

```typescript
export const TEST_CONFIG = {
  performance: {
    maxConcurrentTasks: 10,        // 最大并发任务数
    maxExecutionTime: 120000,      // 最大执行时间
    memoryThreshold: 512 * 1024 * 1024, // 内存阈值
    cpuThreshold: 85               // CPU阈值
  },
  errorInjection: {
    networkFailureRate: 0.1,       // 网络故障率
    timeoutRate: 0.05,             // 超时故障率
    accountFailureRate: 0.15       // 账号故障率
  }
};
```

## 🐛 故障排除

### 常见问题

1. **测试超时**
   ```
   解决方案: 增加 testTimeout 或优化测试代码
   ```

2. **内存不足**
   ```
   解决方案: 减少 maxWorkers 或增加系统内存
   ```

3. **端口冲突**
   ```
   解决方案: 确保测试环境端口可用或修改配置
   ```

4. **依赖缺失**
   ```
   解决方案: 运行 pnpm install 确保所有依赖已安装
   ```

### 调试模式

```bash
# 启用详细日志
DEBUG=* pnpm run test:e2e

# 运行单个测试文件
pnpm run test:e2e -- test/e2e/integration/complete-data-flow.test.ts

# 启用覆盖率报告
pnpm run test:e2e -- --coverage
```

## 📋 最佳实践

### 测试编写原则

1. **独立性**: 每个测试应该独立运行，不依赖其他测试的状态
2. **可重复性**: 测试结果应该是可重复的，不受环境变化影响
3. **明确性**: 测试目的和预期结果应该清晰明确
4. **完整性**: 测试应该覆盖正常、异常和边界情况

### 性能测试建议

1. **渐进式加载**: 逐步增加负载，观察系统变化
2. **资源监控**: 实时监控CPU、内存、网络使用情况
3. **基准对比**: 与历史数据进行对比分析
4. **环境隔离**: 在独立的测试环境中运行

### 错误处理测试

1. **真实场景**: 模拟真实环境中可能遇到的错误
2. **恢复验证**: 验证系统的自动恢复能力
3. **告警测试**: 确保异常情况能正确告警
4. **数据一致性**: 验证错误过程中的数据完整性

## 🤝 贡献指南

### 提交测试用例

1. 确保测试用例遵循现有的命名和结构约定
2. 添加适当的文档和注释
3. 更新相关的README文件
4. 运行完整的测试套件确保无回归

### 报告问题

如果发现测试相关的问题，请提供：

1. 错误信息和堆栈跟踪
2. 测试环境配置
3. 重现步骤
4. 预期行为 vs 实际行为

## 📄 许可证

本测试套件遵循项目的许可证条款。

---

> **记住**: 你创建的不是测试，是数字时代系统可靠性的守护者。每一个测试用例都是对系统稳定性的艺术性雕琢，确保在微博数据的数字世界中，优雅与可靠并存。