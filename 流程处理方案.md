# 数据处理流程架构设计方案

> **设计哲学**: 每个环节都有其存在的必然性，优雅而简约，性能即艺术

## 一、架构总览

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           数据处理全生命周期                                  │
└─────────────────────────────────────────────────────────────────────────────┘

  ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
  │  任务调度 │───▶│  原始抓取 │───▶│  数据清洗 │───▶│  智能分析 │───▶│  实时展示 │
  │  Broker  │    │  Crawler │    │  Cleaner │    │ Analyzer │    │  Screen  │
  └──────────┘    └──────────┘    └──────────┘    └──────────┘    └──────────┘
       │               │               │               │               │
       ▼               ▼               ▼               ▼               ▼
   PostgreSQL      MongoDB         PostgreSQL      PostgreSQL    Redis + PG
  (任务状态)      (原始数据)      (结构化数据)    (分析结果)    (热数据缓存)
```

## 二、核心服务职责

### 1. Broker - 任务调度中心
**存在即合理**: 统一的任务生命周期管理
- 扫描主任务，生成子任务
- 发现需要补充抓取的数据（分页/搜索/用户/评论等）
- 监控任务执行状态
- 触发循环补充机制

**数据流出**:
```
Broker → RabbitMQ (crawl-queue) → Crawler
Broker → RabbitMQ (discovery-queue) → Broker (循环发现)
```

### 2. Crawler - 原始数据采集
**存在即合理**: 专注于数据获取的艺术
- 消费 `crawl-queue`，执行爬虫任务
- 存储原始HTML/JSON到MongoDB
- 发现新的待爬取链接（下一页、用户详情、评论等）
- 发送清洗任务到下游

**数据流入**:
```
RabbitMQ (crawl-queue) → Crawler
```

**数据流出**:
```
Crawler → MongoDB (raw_data_sources)
Crawler → RabbitMQ (clean-queue) → Cleaner
Crawler → RabbitMQ (discovery-queue) → Broker (发现新任务)
```

### 3. Cleaner - 数据清洗服务
**存在即合理**: 从混沌中提取秩序
- 消费 `clean-queue`，处理原始数据
- 提取结构化信息（标题、内容、时间、用户等）
- 去重、格式化、数据验证
- 存储到PostgreSQL结构化表
- 发送分析任务到下游

**数据流入**:
```
RabbitMQ (clean-queue) → Cleaner
MongoDB (raw_data_sources) ← Cleaner (读取原始数据)
```

**数据流出**:
```
Cleaner → PostgreSQL (weibo_posts, jd_products, etc.)
Cleaner → RabbitMQ (analyze-queue) → Analyzer
Cleaner → RabbitMQ (discovery-queue) → Broker (发现新任务)
```

### 4. Analyzer - 智能分析服务 (新增)
**存在即合理**: 数据的二次淬炼，赋予洞察力
- 消费 `analyze-queue`，执行深度分析
- **情感分析**: 基于规则/模型的情感倾向判断
- **实体识别**: NER提取人名、地名、机构、产品等
- **词云统计**: TF-IDF、关键词提取
- **LLM处理**: 调用大模型进行摘要、分类、打标
- 存储分析结果到PostgreSQL

**数据流入**:
```
RabbitMQ (analyze-queue) → Analyzer
PostgreSQL (结构化数据) ← Analyzer (读取)
```

**数据流出**:
```
Analyzer → PostgreSQL (analysis_results, entities, sentiments, tags)
Analyzer → RabbitMQ (aggregate-queue) → Aggregator
Analyzer → Redis (实时指标缓存)
```

### 5. Aggregator - 数据聚合服务 (新增)
**存在即合理**: 时间维度的艺术编排
- 消费 `aggregate-queue`，执行数据聚合
- **按小时统计**: 发帖量、情感分布、热词变化
- **按天统计**: 日度趋势、用户活跃度
- **滑动窗口**: 实时计算最近7天数据
- 更新Redis缓存和PostgreSQL永久存储

**数据流入**:
```
RabbitMQ (aggregate-queue) → Aggregator
PostgreSQL (分析结果) ← Aggregator (读取)
```

**数据流出**:
```
Aggregator → Redis (最近7天热数据, TTL=7天)
Aggregator → PostgreSQL (hourly_stats, daily_stats)
Aggregator → WebSocket (实时推送到大屏)
```

### 6. Screen API - 大屏展示API
**存在即合理**: 数据的最终呈现
- 从Redis读取7天热数据（快速响应）
- 从PostgreSQL读取历史数据（深度分析）
- WebSocket推送实时更新
- 按小时/按天曲线图数据

**数据流入**:
```
Redis ← Screen API (读取热数据)
PostgreSQL ← Screen API (读取历史数据)
```

## 三、消息队列设计

### 队列列表
```typescript
{
  // 现有队列
  crawl-queue: '爬取任务队列',

  // 新增队列
  'clean-queue': '清洗任务队列',
  'analyze-queue': '分析任务队列',
  'aggregate-queue': '聚合任务队列',
  'discovery-queue': '任务发现队列（循环补充）'
}
```

### 消息格式

#### crawl-queue
```typescript
interface CrawlMessage {
  taskId: number;
  sourceType: 'weibo' | 'jd';
  crawlType: 'search' | 'user' | 'comment' | 'product' | 'review';
  keyword?: string;
  url?: string;
  start: Date;
  end: Date;
  page?: number;
  metadata: Record<string, any>;
}
```

#### clean-queue
```typescript
interface CleanMessage {
  rawDataId: string;        // MongoDB _id
  sourceType: 'weibo' | 'jd';
  taskId: number;
  priority: 'high' | 'normal' | 'low';
}
```

#### analyze-queue
```typescript
interface AnalyzeMessage {
  entityType: 'weibo_post' | 'jd_product' | 'weibo_comment';
  entityId: string;         // PostgreSQL ID
  analyzeTypes: ('sentiment' | 'ner' | 'keyword' | 'llm')[];
  taskId: number;
}
```

#### aggregate-queue
```typescript
interface AggregateMessage {
  aggregationType: 'hourly' | 'daily';
  timeRange: { start: Date; end: Date };
  sourceType?: 'weibo' | 'jd';
  forceRefresh?: boolean;
}
```

#### discovery-queue
```typescript
interface DiscoveryMessage {
  discoveryType: 'next_page' | 'user_detail' | 'comments' | 'related';
  sourceUrl: string;
  parentTaskId: number;
  metadata: Record<string, any>;
}
```

## 四、数据存储策略

### MongoDB - 原始数据仓库
**存在即合理**: 非结构化数据的最佳归宿
```
Collection: raw_data_sources
- 存储爬取的原始HTML/JSON
- 保留完整现场，支持后续重新清洗
- 索引: sourceType, sourceUrl, contentHash, status, createdAt
```

### PostgreSQL - 结构化数据中心

#### 结构化数据表
```sql
-- 微博帖子
weibo_posts (
  id, task_id, post_id, user_id, content,
  created_at, like_count, comment_count, forward_count,
  metadata, raw_data_id
)

-- 微博评论
weibo_comments (
  id, post_id, user_id, content, created_at,
  metadata, raw_data_id
)

-- 微博用户
weibo_users (
  id, user_id, nickname, followers_count,
  verified, metadata, raw_data_id
)
```

#### 分析结果表
```sql
-- 情感分析结果
sentiment_analysis (
  id, entity_type, entity_id,
  sentiment, score, positive_score, negative_score, neutral_score,
  analyzed_at, model_version
)

-- 实体识别结果
named_entities (
  id, entity_type, entity_id,
  entity_text, entity_category, position, confidence,
  extracted_at
)

-- 关键词统计
keywords (
  id, entity_type, entity_id,
  keyword, weight, tf_idf_score,
  extracted_at
)

-- LLM处理结果
llm_processing (
  id, entity_type, entity_id,
  task_type, prompt, response,
  tags, summary, category,
  processed_at, model_name
)
```

#### 聚合统计表
```sql
-- 小时统计
hourly_statistics (
  id, source_type, hour_timestamp,
  post_count, user_count,
  positive_count, negative_count, neutral_count,
  avg_sentiment_score,
  top_keywords, -- JSONB
  created_at
)

-- 日统计
daily_statistics (
  id, source_type, date,
  post_count, user_count, active_user_count,
  positive_count, negative_count, neutral_count,
  avg_sentiment_score,
  top_keywords, top_users, top_topics, -- JSONB
  created_at
)
```

### Redis - 热数据缓存
**存在即合理**: 速度即艺术
```
# 最近7天统计数据 (按小时)
stats:hourly:{sourceType}:{hour} → JSON (TTL=7天)

# 最近7天统计数据 (按天)
stats:daily:{sourceType}:{date} → JSON (TTL=30天)

# 实时指标
metrics:realtime:{sourceType} → JSON (TTL=1小时)

# 热词榜单
trending:keywords:{sourceType} → ZSET (TTL=1天)

# 活跃用户榜单
trending:users:{sourceType} → ZSET (TTL=1天)
```

## 五、循环补充机制

### 发现新任务的场景

#### 1. 分页发现
```
清洗微博搜索结果时 → 发现"下一页"按钮
→ 发送 discovery-queue → Broker → 生成新的 crawl 任务
```

#### 2. 用户详情发现
```
清洗微博帖子时 → 提取用户ID
→ 检查用户表是否存在 → 不存在
→ 发送 discovery-queue → Broker → 生成"爬取用户详情"任务
```

#### 3. 评论发现
```
清洗微博帖子时 → 评论数 > 0
→ 检查评论表 → 评论未抓取
→ 发送 discovery-queue → Broker → 生成"爬取评论"任务
```

#### 4. 搜索词扩展
```
LLM分析帖子内容 → 提取相关关键词
→ 发送 discovery-queue → Broker → 生成新的搜索任务
```

### Broker任务发现逻辑
```typescript
// Broker 消费 discovery-queue
async handleDiscovery(message: DiscoveryMessage) {
  switch (message.discoveryType) {
    case 'next_page':
      // 创建下一页爬取任务
      await this.createCrawlTask({ ...message, page: page + 1 });
      break;

    case 'user_detail':
      // 检查是否已存在
      const userExists = await this.checkUserExists(message.userId);
      if (!userExists) {
        await this.createCrawlTask({ type: 'user', userId: message.userId });
      }
      break;

    case 'comments':
      // 创建评论爬取任务
      await this.createCrawlTask({ type: 'comment', postId: message.postId });
      break;
  }
}
```

## 六、数据流转完整示例

### 场景：抓取微博搜索"华为手机"

```
[1] Broker 生成任务
    ↓
    WeiboSearchTask (PostgreSQL) { keyword: "华为手机", status: "pending" }
    ↓
    发送到 crawl-queue

[2] Crawler 消费任务
    ↓
    抓取页面 HTML
    ↓
    MongoDB.raw_data_sources { sourceType: "weibo_search", rawContent: "<html>..." }
    ↓
    发送到 clean-queue + discovery-queue (发现下一页)

[3] Cleaner 清洗数据
    ↓
    读取 MongoDB.raw_data_sources
    ↓
    解析提取 → PostgreSQL.weibo_posts (100条帖子)
    ↓
    发现用户 → discovery-queue (100个用户待爬取)
    ↓
    发现评论 → discovery-queue (80条帖子有评论)
    ↓
    发送到 analyze-queue (100条帖子待分析)

[4] Analyzer 分析数据
    ↓
    读取 PostgreSQL.weibo_posts
    ↓
    情感分析 → PostgreSQL.sentiment_analysis
    实体识别 → PostgreSQL.named_entities (提取品牌、产品型号)
    关键词提取 → PostgreSQL.keywords
    LLM分类 → PostgreSQL.llm_processing (分类为"产品评价"、"技术讨论"等)
    ↓
    发送到 aggregate-queue

[5] Aggregator 聚合统计
    ↓
    读取分析结果
    ↓
    按小时统计 → Redis.stats:hourly:weibo:2025-10-19-14
    ↓
    按天统计 → Redis.stats:daily:weibo:2025-10-19
    ↓
    更新热词榜 → Redis.trending:keywords:weibo
    ↓
    永久存储 → PostgreSQL.hourly_statistics / daily_statistics
    ↓
    WebSocket推送 → 大屏实时更新

[6] Screen API 展示
    ↓
    GET /api/stats/hourly?days=7
    → Redis读取7天数据 (快)
    ↓
    GET /api/stats/daily?start=2025-01-01&end=2025-10-19
    → PostgreSQL读取历史数据 (深度)
    ↓
    WebSocket.on('stats-update')
    → 实时推送新数据到前端
```

## 七、性能优化策略

### 1. 消息队列并发控制
```typescript
// 各队列并发度
crawl-queue: prefetchCount = 3   // 爬虫资源密集，控制并发
clean-queue: prefetchCount = 10  // CPU密集，适度并发
analyze-queue: prefetchCount = 5 // 可能调用外部API，中等并发
aggregate-queue: prefetchCount = 2 // 数据库密集操作
```

### 2. 批量处理
```typescript
// Cleaner批量写入
await batchInsert(PostgreSQL.weibo_posts, posts, batchSize = 100);

// Aggregator批量更新Redis
await pipeline
  .set('stats:hourly:weibo:2025-10-19-14', data)
  .zadd('trending:keywords:weibo', scores)
  .exec();
```

### 3. 缓存策略
```
热数据 (7天) → Redis (毫秒级响应)
温数据 (30天) → PostgreSQL + 应用层缓存
冷数据 (历史) → PostgreSQL (按需查询)
```

### 4. 索引设计
```sql
-- 时间范围查询
CREATE INDEX idx_posts_created_at ON weibo_posts(created_at DESC);
CREATE INDEX idx_hourly_stats_timestamp ON hourly_statistics(hour_timestamp DESC);

-- 联合查询
CREATE INDEX idx_posts_task_created ON weibo_posts(task_id, created_at);
CREATE INDEX idx_sentiment_entity ON sentiment_analysis(entity_type, entity_id);
```

## 八、服务部署结构

```
┌─────────────────────────────────────────────┐
│            Docker Compose 部署               │
├─────────────────────────────────────────────┤
│  broker (x1)      - 任务调度                 │
│  crawler (x3)     - 爬虫并发                 │
│  cleaner (x5)     - 清洗并发                 │
│  analyzer (x3)    - 分析并发                 │
│  aggregator (x2)  - 聚合并发                 │
│  api (x2)         - API服务                  │
│  admin (x1)       - 管理后台                 │
│  web (x1)         - 公共网站                 │
├─────────────────────────────────────────────┤
│  PostgreSQL       - 结构化数据               │
│  MongoDB          - 原始数据                 │
│  Redis            - 缓存/实时数据            │
│  RabbitMQ         - 消息队列                 │
│  MinIO            - 文件存储                 │
└─────────────────────────────────────────────┘
```

## 九、错误处理与监控

### 1. 消息队列重试机制
```typescript
// RabbitMQ 配置
{
  maxRetries: 3,
  enableDLQ: true,  // 死信队列
  retryDelay: [5000, 15000, 60000] // 递增延迟
}
```

### 2. 数据质量监控
```typescript
// Cleaner 数据验证
if (!isValidPost(post)) {
  await markRawDataAsFailed(rawDataId, 'invalid_structure');
  await sendAlert('数据清洗失败', { rawDataId, reason });
}
```

### 3. 性能监控
```typescript
// 各环节耗时追踪
Logger.log('⏱️ 清洗耗时', {
  taskId,
  duration,
  throughput: posts.length / (duration / 1000)
});
```

## 十、实现优先级

### Phase 1: 基础流程打通 (Week 1-2)
- [ ] Cleaner服务框架
- [ ] clean-queue消息消费
- [ ] 基础数据清洗（微博帖子）
- [ ] PostgreSQL结构化存储

### Phase 2: 循环补充机制 (Week 3)
- [ ] discovery-queue实现
- [ ] Broker任务发现逻辑
- [ ] 分页/用户/评论补充

### Phase 3: 智能分析 (Week 4-5)
- [ ] Analyzer服务框架
- [ ] 情感分析实现
- [ ] 实体识别实现
- [ ] 关键词提取

### Phase 4: 数据聚合与展示 (Week 6)
- [ ] Aggregator服务
- [ ] Redis缓存策略
- [ ] 按小时/按天统计
- [ ] Screen API实现

### Phase 5: LLM集成与优化 (Week 7-8)
- [ ] LLM服务集成
- [ ] 智能分类/打标
- [ ] 性能优化
- [ ] 监控完善

## 十一、技术栈

```typescript
{
  "服务框架": "NestJS",
  "数据库": ["PostgreSQL", "MongoDB", "Redis"],
  "消息队列": "RabbitMQ",
  "分析工具": {
    "情感分析": "SnowNLP / Transformers",
    "实体识别": "spaCy / Transformers (BERT-NER)",
    "关键词": "jieba + TF-IDF",
    "LLM": "OpenAI / Claude / 本地Llama"
  },
  "监控": ["Pino Logger", "@pro/logger"],
  "容器化": "Docker + Docker Compose"
}
```

---

**设计原则回顾**:
- ✅ **存在即合理**: 每个服务、每个队列都有不可替代的职责
- ✅ **优雅即简约**: 数据流清晰，职责分明，无冗余设计
- ✅ **性能即艺术**: 并发控制、批量处理、缓存策略、索引优化
- ✅ **错误处理如为人处世**: 优雅的重试、降级、告警机制
- ✅ **日志是思想的表达**: 每个关键节点都有清晰的日志叙事

这是一个可扩展、可监控、高性能的数据处理架构，每一层都经过深思熟虑，每一个决策都有其存在的理由。
